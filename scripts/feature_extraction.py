# scripts/feature_extraction.py
"""
Ä°Ã§ Mekan Benzerlik Arama Sistemi - Ã–zellik Ã‡Ä±karÄ±mÄ±
Manuel eklenen gÃ¶rsellerden Ã¶zellik Ã§Ä±karÄ±mÄ±
"""

import os
import sys
import numpy as np
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image, ImageStat
import pandas as pd
from tqdm import tqdm
import cv2
import joblib
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import json

# Ana dizini Python path'ine ekle
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Config bilgileri (config.py yoksa default deÄŸerler)
try:
    from config import *
except ImportError:
    print("âš ï¸ config.py bulunamadÄ±, default ayarlar kullanÄ±lÄ±yor...")
    DATA_DIR = "data"
    MODELS_DIR = "models" 
    RESULTS_DIR = "results"
    IMAGE_SIZE = (224, 224)
    SUPPORTED_FORMATS = ['.jpg', '.jpeg', '.png', '.bmp']
    MIN_IMAGE_SIZE = (224, 224)
    PCA_COMPONENTS = 128
    BATCH_SIZE = 16

class FeatureExtractor:
    def __init__(self, device='auto'):
        """
        Ã–zellik Ã§Ä±karÄ±m sÄ±nÄ±fÄ± - manuel gÃ¶rsellerden Ã¶zellik Ã§Ä±karÄ±r
        """
        # Cihaz seÃ§imi
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        print(f"ğŸ”§ KullanÄ±lan cihaz: {self.device}")
        if torch.cuda.is_available():
            print(f"   GPU: {torch.cuda.get_device_name(0)}")
            print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        # Modelleri yÃ¼kle
        self._setup_models()
        self._setup_transforms()
    
    def _setup_models(self):
        """ResNet-50 modelini yÃ¼kle"""
        print("ğŸ“¦ ResNet-50 modeli yÃ¼kleniyor...")
        
        # ResNet-50 Ã¶nceden eÄŸitilmiÅŸ model
        self.resnet = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')
        
        # Son classification katmanÄ±nÄ± kaldÄ±r (sadece features)
        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])
        
        # Evaluation moduna al
        self.resnet.eval()
        self.resnet.to(self.device)
        
        # Gradyan hesaplama kapalÄ± (sadece inference)
        for param in self.resnet.parameters():
            param.requires_grad = False
        
        print("âœ… ResNet-50 hazÄ±r (2048 boyutlu Ã¶zellik vektÃ¶rÃ¼)")
    
    def _setup_transforms(self):
        """GÃ¶rsel Ã¶n iÅŸleme dÃ¶nÃ¼ÅŸÃ¼mleri"""
        self.transform = transforms.Compose([
            transforms.Resize(IMAGE_SIZE),  # 224x224'e yeniden boyutlandÄ±r
            transforms.ToTensor(),          # PIL -> Tensor
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],  # ImageNet ortalamasÄ±
                std=[0.229, 0.224, 0.225]    # ImageNet standart sapmasÄ±
            )
        ])
        print("âœ… GÃ¶rsel dÃ¶nÃ¼ÅŸÃ¼mleri hazÄ±r")
    
    def validate_image(self, image_path):
        """GÃ¶rselin kullanÄ±labilir olup olmadÄ±ÄŸÄ±nÄ± kontrol et"""
        try:
            # Dosya var mÄ±?
            if not os.path.exists(image_path):
                return False, "Dosya bulunamadÄ±"
            
            # PIL ile aÃ§Ä±labiliyor mu?
            img = Image.open(image_path).convert('RGB')
            width, height = img.size
            
            # Ã‡ok kÃ¼Ã§Ã¼k mÃ¼?
            if width < MIN_IMAGE_SIZE[0] or height < MIN_IMAGE_SIZE[1]:
                return False, f"Ã‡ok kÃ¼Ã§Ã¼k: {width}x{height}"
            
            # Ã‡ok aÅŸÄ±rÄ± aspect ratio?
            aspect_ratio = width / height
            if aspect_ratio > 10 or aspect_ratio < 0.1:
                return False, f"AÅŸÄ±rÄ± en-boy oranÄ±: {aspect_ratio:.2f}"
            
            # BulanÄ±k mÄ±? (OpenCV ile)
            try:
                cv_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
                if cv_img is not None:
                    blur_measure = cv2.Laplacian(cv_img, cv2.CV_64F).var()
                    if blur_measure < 10:  # Ã‡ok bulanÄ±k
                        return False, f"Ã‡ok bulanÄ±k: {blur_measure:.1f}"
            except:
                pass  # OpenCV hatasÄ± olursa geÃ§
            
            # Renk Ã§eÅŸitliliÄŸi var mÄ±?
            stat = ImageStat.Stat(img)
            if sum(stat.stddev) < 5:  # Tek renkli
                return False, f"Tek renkli/dÃ¼ÅŸÃ¼k kontrast"
            
            return True, "âœ… GeÃ§erli"
            
        except Exception as e:
            return False, f"Hata: {str(e)}"
    
    def extract_single_image_features(self, image_path):
        """Tek gÃ¶rselden Ã¶zellik Ã§Ä±kar"""
        try:
            # Ã–nce gÃ¶rseli validate et
            is_valid, reason = self.validate_image(image_path)
            if not is_valid:
                return None, reason
            
            # GÃ¶rseli yÃ¼kle ve dÃ¶nÃ¼ÅŸtÃ¼r
            image = Image.open(image_path).convert('RGB')
            tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # Ã–zellik Ã§Ä±karÄ±mÄ±
            with torch.no_grad():
                features = self.resnet(tensor)
                features = features.squeeze().flatten()  # (2048,) boyutunda
            
            return features.cpu().numpy(), "âœ… BaÅŸarÄ±lÄ±"
            
        except Exception as e:
            return None, f"âŒ Ã–zellik Ã§Ä±karÄ±m hatasÄ±: {str(e)}"
    
    def scan_data_directory(self):
        """data/ klasÃ¶rÃ¼ndeki tÃ¼m gÃ¶rselleri tara"""
        print("ğŸ” Veri klasÃ¶rÃ¼ taranÄ±yor...")
        
        categories = ['living_rooms', 'bedrooms', 'kitchens', 'bathrooms', 'dining_rooms']
        all_images = []
        
        for category in categories:
            category_path = os.path.join(DATA_DIR, category)
            
            if not os.path.exists(category_path):
                print(f"âš ï¸  KlasÃ¶r bulunamadÄ±: {category_path}")
                continue
            
            # Bu kategorideki dosyalarÄ± bul
            files = []
            for file in os.listdir(category_path):
                file_lower = file.lower()
                if any(file_lower.endswith(ext) for ext in SUPPORTED_FORMATS):
                    files.append(file)
            
            print(f"ğŸ“ {category}: {len(files)} dosya bulundu")
            
            # Dosya bilgilerini topla
            for filename in files:
                filepath = os.path.join(category_path, filename)
                try:
                    filesize = os.path.getsize(filepath)
                    all_images.append({
                        'filepath': filepath,
                        'filename': filename,
                        'category': category,
                        'filesize': filesize
                    })
                except:
                    print(f"  âš ï¸ Dosya okunamadÄ±: {filename}")
        
        print(f"\nğŸ“Š Toplam {len(all_images)} gÃ¶rsel bulundu")
        
        # Kategori Ã¶zeti
        if all_images:
            df = pd.DataFrame(all_images)
            print("\nğŸ“ˆ Kategori DaÄŸÄ±lÄ±mÄ±:")
            category_counts = df['category'].value_counts()
            for category, count in category_counts.items():
                print(f"  ğŸ“¸ {category.replace('_', ' ').title()}: {count} gÃ¶rsel")
        
        return all_images
    
    def extract_features_from_list(self, image_list):
        """GÃ¶rsel listesinden toplu Ã¶zellik Ã§Ä±karÄ±mÄ±"""
        print(f"\nğŸ§  {len(image_list)} gÃ¶rselden Ã¶zellik Ã§Ä±karÄ±mÄ± baÅŸlÄ±yor...")
        
        all_features = []
        valid_metadata = []
        failed_count = 0
        
        # Progress bar ile her gÃ¶rseli iÅŸle
        for item in tqdm(image_list, desc="Ã–zellik Ã§Ä±karÄ±mÄ±", unit="gÃ¶rsel"):
            features, message = self.extract_single_image_features(item['filepath'])
            
            if features is not None:
                all_features.append(features)
                valid_metadata.append(item)
            else:
                failed_count += 1
                # Ä°lk 5 hatayÄ± gÃ¶ster
                if failed_count <= 5:
                    print(f"\n  âŒ {item['filename']}: {message}")
        
        if not all_features:
            print("âŒ HiÃ§ Ã¶zellik Ã§Ä±karÄ±lamadÄ±!")
            return None, None
        
        # NumPy array'e Ã§evir
        features_array = np.array(all_features)
        metadata_df = pd.DataFrame(valid_metadata)
        
        print(f"\nâœ… Ã–zellik Ã§Ä±karÄ±mÄ± tamamlandÄ±:")
        print(f"  ğŸ¯ BaÅŸarÄ±lÄ±: {len(all_features)} gÃ¶rsel")
        print(f"  âŒ BaÅŸarÄ±sÄ±z: {failed_count} gÃ¶rsel")
        print(f"  ğŸ“ Ã–zellik boyutu: {features_array.shape}")
        
        return features_array, metadata_df
    
    def apply_pca_reduction(self, features):
        """PCA ile boyut indirgeme"""
        print(f"\nğŸ“Š PCA boyut indirgeme ({PCA_COMPONENTS} bileÅŸen)...")
        
        # PCA modelini eÄŸit
        pca = PCA(n_components=PCA_COMPONENTS, random_state=42)
        features_pca = pca.fit_transform(features)
        
        # AÃ§Ä±klanan varyans analizi
        explained_variance = np.sum(pca.explained_variance_ratio_)
        print(f"  ğŸ“ˆ AÃ§Ä±klanan toplam varyans: {explained_variance*100:.1f}%")
        
        # PCA grafiÄŸi Ã§iz
        self.plot_pca_analysis(pca)
        
        # PCA modelini kaydet
        pca_path = os.path.join(MODELS_DIR, 'pca_model.pkl')
        joblib.dump(pca, pca_path)
        print(f"  ğŸ’¾ PCA modeli kaydedildi: {pca_path}")
        
        return features_pca, pca
    
    def plot_pca_analysis(self, pca):
        """PCA analiz grafikleri"""
        plt.figure(figsize=(15, 5))
        
        # 1. KÃ¼mÃ¼latif aÃ§Ä±klanan varyans
        plt.subplot(1, 3, 1)
        cumsum = np.cumsum(pca.explained_variance_ratio_)
        plt.plot(range(1, len(cumsum) + 1), cumsum, 'bo-', linewidth=2)
        plt.axhline(y=0.95, color='r', linestyle='--', alpha=0.7, label='%95')
        plt.axhline(y=0.90, color='orange', linestyle='--', alpha=0.7, label='%90')
        plt.xlabel('BileÅŸen SayÄ±sÄ±')
        plt.ylabel('KÃ¼mÃ¼latif AÃ§Ä±klanan Varyans')
        plt.title('PCA KÃ¼mÃ¼latif Varyans')
        plt.grid(True, alpha=0.3)
        plt.legend()
        
        # 2. Ä°lk 20 bileÅŸenin bireysel varyansÄ±
        plt.subplot(1, 3, 2)
        plt.bar(range(1, min(21, len(pca.explained_variance_ratio_) + 1)), 
                pca.explained_variance_ratio_[:20])
        plt.xlabel('BileÅŸen')
        plt.ylabel('AÃ§Ä±klanan Varyans')
        plt.title('Ä°lk 20 BileÅŸen VaryansÄ±')
        plt.xticks(range(1, min(21, len(pca.explained_variance_ratio_) + 1)))
        
        # 3. Varyans daÄŸÄ±lÄ±mÄ±
        plt.subplot(1, 3, 3)
        plt.semilogy(pca.explained_variance_ratio_, 'go-')
        plt.xlabel('BileÅŸen')
        plt.ylabel('AÃ§Ä±klanan Varyans (log)')
        plt.title('Varyans DaÄŸÄ±lÄ±mÄ± (Log Scale)')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Kaydet
        plot_path = os.path.join(RESULTS_DIR, 'pca_analysis.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        print(f"  ğŸ“Š PCA analiz grafiÄŸi: {plot_path}")
        plt.show()
        
        # %95 varyans iÃ§in gerekli bileÅŸen sayÄ±sÄ±
        variance_95_idx = np.argmax(cumsum >= 0.95) + 1
        variance_90_idx = np.argmax(cumsum >= 0.90) + 1
        print(f"  ğŸ“ %90 varyans: {variance_90_idx} bileÅŸen")
        print(f"  ğŸ“ %95 varyans: {variance_95_idx} bileÅŸen")
    
    def save_results(self, features, metadata_df, raw_features=None):
        """SonuÃ§larÄ± kaydet"""
        print("\nğŸ’¾ SonuÃ§lar kaydediliyor...")
        
        # Ä°ndirgenen Ã¶zellikler
        features_path = os.path.join(MODELS_DIR, 'features.npy')
        np.save(features_path, features)
        print(f"  âœ… Ã–zellikler: {features_path}")
        
        # Ham Ã¶zellikler (opsiyonel)
        if raw_features is not None:
            raw_features_path = os.path.join(MODELS_DIR, 'raw_features.npy')
            np.save(raw_features_path, raw_features)
            print(f"  âœ… Ham Ã¶zellikler: {raw_features_path}")
        
        # Metadata
        metadata_path = os.path.join(MODELS_DIR, 'image_metadata.csv')
        metadata_df.to_csv(metadata_path, index=False, encoding='utf-8')
        print(f"  âœ… Metadata: {metadata_path}")
        
        # Dataset istatistikleri
        stats = {
            'extraction_date': pd.Timestamp.now().isoformat(),
            'total_images': len(metadata_df),
            'feature_dimension': features.shape[1],
            'raw_feature_dimension': raw_features.shape[1] if raw_features is not None else 'N/A',
            'categories': metadata_df['category'].value_counts().to_dict(),
            'file_sizes': {
                'min_mb': metadata_df['filesize'].min() / 1024**2,
                'max_mb': metadata_df['filesize'].max() / 1024**2,
                'avg_mb': metadata_df['filesize'].mean() / 1024**2
            }
        }
        
        stats_path = os.path.join(MODELS_DIR, 'dataset_stats.json')
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"  ğŸ“Š Ä°statistikler: {stats_path}")
        
        return features_path, metadata_path, stats_path
    
    def run_complete_pipeline(self):
        """Tam Ã¶zellik Ã§Ä±karÄ±m iÅŸlemi"""
        print("ğŸš€ Ä°Ã§ Mekan Ã–zellik Ã‡Ä±karÄ±m Pipeline'Ä±")
        print("=" * 60)
        
        # Gerekli klasÃ¶rleri oluÅŸtur
        os.makedirs(MODELS_DIR, exist_ok=True)
        os.makedirs(RESULTS_DIR, exist_ok=True)
        
        try:
            # 1. Veri tarama
            image_list = self.scan_data_directory()
            
            if not image_list:
                print("âŒ HiÃ§ gÃ¶rsel bulunamadÄ±!")
                print("\nğŸ’¡ Ã‡Ã¶zÃ¼m:")
                print("   1. data/ klasÃ¶rÃ¼ne ÅŸu alt klasÃ¶rleri oluÅŸturun:")
                print("      - living_rooms/")
                print("      - bedrooms/") 
                print("      - kitchens/")
                print("      - bathrooms/")
                print("      - dining_rooms/")
                print("   2. Her klasÃ¶re en az birkaÃ§ JPG/PNG gÃ¶rsel ekleyin")
                return False
            
            # 2. Ã–zellik Ã§Ä±karÄ±mÄ±
            raw_features, metadata_df = self.extract_features_from_list(image_list)
            
            if raw_features is None:
                print("âŒ Ã–zellik Ã§Ä±karÄ±mÄ± baÅŸarÄ±sÄ±z!")
                return False
            
            # 3. PCA boyut indirgeme
            reduced_features, pca_model = self.apply_pca_reduction(raw_features)
            
            # 4. SonuÃ§larÄ± kaydet
            features_path, metadata_path, stats_path = self.save_results(
                reduced_features, metadata_df, raw_features
            )
            
            # 5. BaÅŸarÄ± raporu
            print("\nğŸ‰ Ã–zellik Ã‡Ä±karÄ±mÄ± BaÅŸarÄ±yla TamamlandÄ±!")
            print("=" * 60)
            print(f"ğŸ“Š Ä°ÅŸlenen gÃ¶rseller: {len(metadata_df)}")
            print(f"ğŸ“ Ham Ã¶zellik boyutu: 2048")
            print(f"ğŸ“‰ PCA Ã¶zellik boyutu: {reduced_features.shape[1]}")
            print(f"ğŸ’¾ Kaydedilen dosyalar:")
            print(f"   â€¢ {features_path}")
            print(f"   â€¢ {metadata_path}")
            print(f"   â€¢ {os.path.join(MODELS_DIR, 'pca_model.pkl')}")
            print(f"   â€¢ {stats_path}")
            print("\nğŸš€ Sonraki adÄ±m:")
            print("   python scripts/similarity_search.py")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ Pipeline hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return False

def check_data_directory():
    """Data klasÃ¶r yapÄ±sÄ±nÄ± kontrol et"""
    print("ğŸ” Veri klasÃ¶rÃ¼ kontrolÃ¼...")
    
    if not os.path.exists(DATA_DIR):
        print(f"âŒ Ana veri klasÃ¶rÃ¼ bulunamadÄ±: {DATA_DIR}")
        return False
    
    categories = ['living_rooms', 'bedrooms', 'kitchens', 'bathrooms', 'dining_rooms']
    missing_categories = []
    empty_categories = []
    
    for category in categories:
        category_path = os.path.join(DATA_DIR, category)
        
        if not os.path.exists(category_path):
            missing_categories.append(category)
        else:
            files = [f for f in os.listdir(category_path) 
                    if any(f.lower().endswith(ext) for ext in SUPPORTED_FORMATS)]
            if len(files) == 0:
                empty_categories.append(category)
            else:
                print(f"  âœ… {category}: {len(files)} gÃ¶rsel")
    
    # Eksik klasÃ¶rler
    if missing_categories:
        print(f"\nâŒ Eksik klasÃ¶rler:")
        for cat in missing_categories:
            print(f"   â€¢ {os.path.join(DATA_DIR, cat)}")
    
    # BoÅŸ klasÃ¶rler  
    if empty_categories:
        print(f"\nâš ï¸ BoÅŸ klasÃ¶rler:")
        for cat in empty_categories:
            print(f"   â€¢ {os.path.join(DATA_DIR, cat)}")
    
    if missing_categories or empty_categories:
        print(f"\nğŸ’¡ Her klasÃ¶re en az birkaÃ§ gÃ¶rsel ekleyin:")
        print(f"   Desteklenen formatlar: {', '.join(SUPPORTED_FORMATS)}")
        return False
    
    print("âœ… Veri klasÃ¶rÃ¼ yapÄ±sÄ± uygun!")
    return True

def main():
    """Ana fonksiyon"""
    print("ğŸ§  Ä°Ã§ Mekan GÃ¶rsel Ã–zellik Ã‡Ä±karÄ±mÄ±")
    print("=" * 50)
    
    # Veri klasÃ¶rÃ¼nÃ¼ kontrol et
    if not check_data_directory():
        print("\nğŸ”§ Ã–nce veri klasÃ¶rlerini dÃ¼zenleyin!")
        return False
    
    # Mevcut Ã¶zellikleri kontrol et
    existing_features = os.path.join(MODELS_DIR, 'features.npy')
    existing_metadata = os.path.join(MODELS_DIR, 'image_metadata.csv')
    
    if os.path.exists(existing_features) and os.path.exists(existing_metadata):
        print(f"\nğŸ”„ Mevcut Ã¶zellikler bulundu!")
        print(f"   â€¢ {existing_features}")
        print(f"   â€¢ {existing_metadata}")
        
        choice = input("\nYeniden Ã§Ä±karÄ±m yapmak istiyor musunuz? (y/N): ").lower().strip()
        if choice != 'y':
            print("âœ… Mevcut Ã¶zellikler kullanÄ±lacak")
            print("ğŸš€ Sonraki adÄ±m: python scripts/similarity_search.py")
            return True
    
    # Ã–zellik Ã§Ä±karÄ±mÄ± baÅŸlat
    extractor = FeatureExtractor()
    success = extractor.run_complete_pipeline()
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)