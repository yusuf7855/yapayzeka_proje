# scripts/data_collection.py
"""
Ä°Ã§ Mekan Benzerlik Arama Sistemi - Veri Toplama
Unsplash ve Pexels API'leri kullanarak gÃ¶rsel indirme
"""

import os
import sys
import requests
from PIL import Image
import time
import json
from tqdm import tqdm

# Ana dizini Python path'ine ekle
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import *

class DataCollector:
    def __init__(self):
        self.unsplash_key = UNSPLASH_ACCESS_KEY
        self.pexels_key = PEXELS_API_KEY
        self.categories = CATEGORIES
        self.data_dir = DATA_DIR
        
        # Veri klasÃ¶rlerini oluÅŸtur
        for category in self.categories.keys():
            os.makedirs(os.path.join(self.data_dir, category), exist_ok=True)
    
    def download_image(self, url, save_path, timeout=10):
        """URL'den gÃ¶rsel indirme"""
        try:
            response = requests.get(url, stream=True, timeout=timeout)
            response.raise_for_status()
            
            with open(save_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            # GÃ¶rselin geÃ§erli olduÄŸunu kontrol et
            img = Image.open(save_path)
            width, height = img.size
            
            # Minimum boyut kontrolÃ¼
            if width < MIN_IMAGE_SIZE[0] or height < MIN_IMAGE_SIZE[1]:
                os.remove(save_path)
                return False, "Ã‡ok kÃ¼Ã§Ã¼k boyut"
            
            # Dosya boyutu kontrolÃ¼
            file_size_mb = os.path.getsize(save_path) / (1024 * 1024)
            if file_size_mb > MAX_FILE_SIZE_MB:
                os.remove(save_path)
                return False, "Dosya Ã§ok bÃ¼yÃ¼k"
            
            img.verify()
            return True, "BaÅŸarÄ±lÄ±"
        
        except Exception as e:
            if os.path.exists(save_path):
                os.remove(save_path)
            return False, str(e)
    
    def search_unsplash_images(self, query, count=30):
        """Unsplash API ile gÃ¶rsel arama"""
        if not self.unsplash_key or self.unsplash_key == "YOUR_UNSPLASH_API_KEY_HERE":
            return []
        
        url = "https://api.unsplash.com/search/photos"
        headers = {"Authorization": f"Client-ID {self.unsplash_key}"}
        
        params = {
            "query": query,
            "per_page": min(count, 30),
            "orientation": "landscape",
            "content_filter": "high"
        }
        
        try:
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            data = response.json()
            
            urls = []
            for photo in data.get('results', []):
                urls.append({
                    'url': photo['urls']['regular'],
                    'id': photo['id'],
                    'description': photo.get('description', ''),
                    'author': photo['user']['name']
                })
            
            return urls
        
        except Exception as e:
            print(f"âŒ Unsplash API hatasÄ±: {e}")
            return []
    
    def search_pexels_images(self, query, count=30):
        """Pexels API ile gÃ¶rsel arama"""
        if not self.pexels_key or self.pexels_key == "YOUR_PEXELS_API_KEY_HERE":
            return []
        
        url = "https://api.pexels.com/v1/search"
        headers = {"Authorization": self.pexels_key}
        
        params = {
            "query": query,
            "per_page": min(count, 80),
            "orientation": "landscape"
        }
        
        try:
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            data = response.json()
            
            urls = []
            for photo in data.get('photos', []):
                urls.append({
                    'url': photo['src']['large'],
                    'id': photo['id'],
                    'description': photo.get('alt', ''),
                    'author': photo['photographer']
                })
            
            return urls
        
        except Exception as e:
            print(f"âŒ Pexels API hatasÄ±: {e}")
            return []
    
    def create_test_images(self):
        """Test gÃ¶rselleri oluÅŸtur (API anahtarÄ± yoksa)"""
        print("ğŸ¨ Test gÃ¶rselleri oluÅŸturuluyor...")
        
        # Her kategori iÃ§in farklÄ± renkler
        colors = [
            (220, 150, 150),  # living_rooms - aÃ§Ä±k kÄ±rmÄ±zÄ±
            (150, 220, 150),  # bedrooms - aÃ§Ä±k yeÅŸil
            (150, 150, 220),  # kitchens - aÃ§Ä±k mavi
            (220, 220, 150),  # bathrooms - aÃ§Ä±k sarÄ±
            (220, 150, 220)   # dining_rooms - aÃ§Ä±k mor
        ]
        
        patterns = ['solid', 'gradient', 'checkerboard', 'stripes']
        
        for i, category in enumerate(self.categories.keys()):
            category_path = os.path.join(self.data_dir, category)
            base_color = colors[i]
            
            for j in range(50):  # Her kategoriden 50 test gÃ¶rseli
                # FarklÄ± desenler oluÅŸtur
                pattern = patterns[j % len(patterns)]
                
                if pattern == 'solid':
                    img = Image.new('RGB', IMAGE_SIZE, base_color)
                
                elif pattern == 'gradient':
                    img = Image.new('RGB', IMAGE_SIZE, base_color)
                    # Basit gradient efekti
                    for x in range(IMAGE_SIZE[0]):
                        for y in range(IMAGE_SIZE[1]):
                            factor = x / IMAGE_SIZE[0]
                            new_color = tuple(int(c * factor) for c in base_color)
                            img.putpixel((x, y), new_color)
                
                elif pattern == 'checkerboard':
                    img = Image.new('RGB', IMAGE_SIZE, base_color)
                    darker_color = tuple(max(0, c - 50) for c in base_color)
                    for x in range(0, IMAGE_SIZE[0], 20):
                        for y in range(0, IMAGE_SIZE[1], 20):
                            if (x // 20 + y // 20) % 2:
                                for dx in range(20):
                                    for dy in range(20):
                                        if x + dx < IMAGE_SIZE[0] and y + dy < IMAGE_SIZE[1]:
                                            img.putpixel((x + dx, y + dy), darker_color)
                
                else:  # stripes
                    img = Image.new('RGB', IMAGE_SIZE, base_color)
                    darker_color = tuple(max(0, c - 30) for c in base_color)
                    for y in range(0, IMAGE_SIZE[1], 10):
                        if (y // 10) % 2:
                            for x in range(IMAGE_SIZE[0]):
                                for dy in range(min(10, IMAGE_SIZE[1] - y)):
                                    img.putpixel((x, y + dy), darker_color)
                
                save_path = os.path.join(category_path, f"test_{j:03d}.jpg")
                img.save(save_path, 'JPEG', quality=85)
            
            print(f"  âœ… {category}: 50 test gÃ¶rseli oluÅŸturuldu")
    
    def collect_real_images(self):
        """GerÃ§ek gÃ¶rselleri API'lerden topla"""
        print("ğŸŒ GerÃ§ek gÃ¶rseller API'lerden indiriliyor...")
        
        total_downloaded = 0
        
        for category, queries in self.categories.items():
            print(f"\nğŸ“ {category.replace('_', ' ').title()} kategorisi...")
            category_path = os.path.join(self.data_dir, category)
            
            img_count = 0
            target_count = MAX_IMAGES_PER_CATEGORY
            
            for query in queries:
                if img_count >= target_count:
                    break
                
                print(f"  ğŸ” Arama: '{query}'")
                
                # Unsplash'dan ara
                unsplash_urls = self.search_unsplash_images(query, count=20)
                
                # Pexels'den ara
                pexels_urls = self.search_pexels_images(query, count=20)
                
                # TÃ¼m URL'leri birleÅŸtir
                all_urls = unsplash_urls + pexels_urls
                
                # Ä°ndir
                for item in tqdm(all_urls, desc=f"  Ä°ndiriliyor", leave=False):
                    if img_count >= target_count:
                        break
                    
                    save_path = os.path.join(category_path, f"{category}_{img_count:03d}.jpg")
                    success, message = self.download_image(item['url'], save_path)
                    
                    if success:
                        img_count += 1
                        total_downloaded += 1
                        
                        # Metadata kaydet
                        metadata = {
                            'filename': os.path.basename(save_path),
                            'source_url': item['url'],
                            'source_id': item['id'],
                            'description': item['description'],
                            'author': item['author'],
                            'query': query,
                            'category': category
                        }
                        
                        metadata_path = save_path.replace('.jpg', '_metadata.json')
                        with open(metadata_path, 'w', encoding='utf-8') as f:
                            json.dump(metadata, f, indent=2, ensure_ascii=False)
                    
                    time.sleep(0.5)  # Rate limiting
                
                time.sleep(1)  # Query arasÄ± bekleme
            
            print(f"  âœ… {category}: {img_count} gÃ¶rsel indirildi")
        
        print(f"\nğŸ‰ Toplam {total_downloaded} gÃ¶rsel baÅŸarÄ±yla indirildi!")
    
    def get_download_statistics(self):
        """Ä°ndirme istatistiklerini gÃ¶ster"""
        print("\nğŸ“Š Veri KÃ¼mesi Ä°statistikleri:")
        print("=" * 40)
        
        total_images = 0
        for category in self.categories.keys():
            category_path = os.path.join(self.data_dir, category)
            if os.path.exists(category_path):
                files = [f for f in os.listdir(category_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
                count = len(files)
                total_images += count
                print(f"ğŸ“ {category.replace('_', ' ').title()}: {count} gÃ¶rsel")
        
        print(f"\nğŸ“ˆ Toplam: {total_images} gÃ¶rsel")
        print(f"ğŸ’¾ Ortalama kategori baÅŸÄ±na: {total_images / len(self.categories):.1f} gÃ¶rsel")
        
        return total_images
    
    def run_data_collection(self):
        """Ana veri toplama fonksiyonu"""
        print("ğŸ“¥ Ä°Ã§ Mekan Veri Toplama BaÅŸlÄ±yor...")
        print("=" * 50)
        
        # API anahtarlarÄ±nÄ± kontrol et
        has_api_keys = (
            self.unsplash_key != "YOUR_UNSPLASH_API_KEY_HERE" or 
            self.pexels_key != "YOUR_PEXELS_API_KEY_HERE"
        )
        
        if has_api_keys:
            print("ğŸ”‘ API anahtarlarÄ± bulundu, gerÃ§ek gÃ¶rseller indiriliyor...")
            self.collect_real_images()
        else:
            print("âš ï¸  API anahtarÄ± bulunamadÄ±, test gÃ¶rselleri oluÅŸturuluyor...")
            print("ğŸ’¡ GerÃ§ek gÃ¶rseller iÃ§in config.py dosyasÄ±nda API anahtarlarÄ±nÄ± gÃ¼ncelleyin")
            self.create_test_images()
        
        # Ä°statistikleri gÃ¶ster
        total = self.get_download_statistics()
        
        if total > 0:
            print("\nâœ… Veri toplama baÅŸarÄ±yla tamamlandÄ±!")
        else:
            print("\nâŒ Veri toplama baÅŸarÄ±sÄ±z oldu!")
        
        return total > 0

if __name__ == "__main__":
    collector = DataCollector()
    success = collector.run_data_collection()
    
    if success:
        print("\nğŸš€ Sonraki adÄ±m: Ã–zellik Ã§Ä±karÄ±mÄ±")
        print("   python scripts/feature_extraction.py")
    else:
        print("\nğŸ”§ Veri toplama sorunlarÄ±nÄ± giderin ve tekrar deneyin")